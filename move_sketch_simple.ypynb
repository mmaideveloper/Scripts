{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924b689b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mediapipe opencv-python \n",
    "!pip install moviepy==1.0.3\n",
    "!pip install numpy pillow diffusers transformers accelerate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b4e067",
   "metadata": {},
   "source": [
    "Background replacement\n",
    "\n",
    "Person sketching or stylization\n",
    "\n",
    "Face anonymization or replacement with a synthetic face\n",
    "\n",
    "Tools You Can Combine\n",
    "\n",
    "Task\t            Tool/Model\t                    Notes\n",
    "\n",
    "Person segmentation\t    MediaPipe, SelfieSegmentation\t        Fast and accurate\n",
    "Background removal\t    rembg, OpenCV\t                        For masking\n",
    "Sketch stylization\t    ControlNet (scribble), custom SD\t    Needs sketch input or edge map\n",
    "Face replacement\t    GFPGAN, InsightFace, FaceFusion\tFor     anonymization\n",
    "Full generative pass\tRunwayML, Stable Diffusion Inpaint\t    Prompt-driven\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e5a2e7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from moviepy.editor import VideoFileClip\n",
    "from moviepy.video.io.ImageSequenceClip import ImageSequenceClip\n",
    "\n",
    "\n",
    "class SketchDanceEditor:\n",
    "    def __init__(\n",
    "            self,\n",
    "            input_path,\n",
    "            output_path,\n",
    "            background_mode=\"color\",      # \"color\", \"image\", \"none\"\n",
    "            background_color=(210, 210, 210),\n",
    "            background_image=None,\n",
    "            clipsec=None,\n",
    "            show_personEdge=False,\n",
    "            sketch_persons=True\n",
    "        ):\n",
    "\n",
    "        self.input_path = input_path\n",
    "        self.output_path = output_path\n",
    "        self.background_mode = background_mode\n",
    "        self.background_color = background_color\n",
    "        self.background_image = background_image\n",
    "        self.clipsec = clipsec\n",
    "        self.show_personEdge = show_personEdge\n",
    "        self.sketch_persons = sketch_persons\n",
    "\n",
    "        self.segmentor = mp.solutions.selfie_segmentation.SelfieSegmentation(model_selection=1)\n",
    "\n",
    "    def detect_person_mask(self, frame):\n",
    "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        result = self.segmentor.process(rgb)\n",
    "        mask = (result.segmentation_mask > 0.5).astype(np.uint8)\n",
    "\n",
    "        # Improve the mask to avoid missing limbs or holes\n",
    "        kernel = np.ones((5, 5), np.uint8)\n",
    "        mask = cv2.dilate(mask, kernel, iterations=2)\n",
    "        mask = cv2.GaussianBlur(mask.astype(np.float32), (9, 9), 0)\n",
    "        mask = (mask > 0.5).astype(np.uint8)\n",
    "\n",
    "        #mask = (mask * 255).astype(np.uint8)\n",
    "        return mask\n",
    "\n",
    "    def sketch_frame(self, frame, mask = None ):\n",
    "        \"\"\"Return a pencil sketch version of frame.\"\"\"\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        inv = 255 - gray\n",
    "        blur = cv2.GaussianBlur(inv, (21, 21), 0)\n",
    "        sketch = cv2.divide(gray, 255 - blur, scale=256)\n",
    "        return cv2.cvtColor(sketch, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    def get_background(self, frame):\n",
    "        \"\"\"Generate background based on chosen mode.\"\"\"\n",
    "        h, w = frame.shape[:2]\n",
    "\n",
    "        if self.background_mode == \"none\":\n",
    "            return frame.copy()\n",
    "\n",
    "        elif self.background_mode == \"color\":\n",
    "            return np.full((h, w, 3), self.background_color, dtype=np.uint8)\n",
    "\n",
    "        elif self.background_mode == \"image\":\n",
    "            if self.background_image is None:\n",
    "                raise ValueError(\"background_mode='image' but no background_image provided\")\n",
    "            return cv2.resize(self.background_image, (w, h))\n",
    "\n",
    "        raise ValueError(f\"Unknown background_mode: {self.background_mode}\")\n",
    "\n",
    "    def process_video(self):\n",
    "        clip = VideoFileClip(self.input_path).subclip(*self.clipsec) if self.clipsec else VideoFileClip(self.input_path)\n",
    "        processed_frames = []\n",
    "\n",
    "        for frame in clip.iter_frames():\n",
    "            mask = self.detect_person_mask(frame)\n",
    "            \n",
    "            # Background (always generated)\n",
    "            background = self.get_background(frame)\n",
    "            \n",
    "            # Composite:\n",
    "            #   foreground where mask==1\n",
    "            #   background everywhere else\n",
    "            if self.background_mode is not None:\n",
    "                foreground = np.where(mask[..., None] == 1, frame, background)\n",
    "            else:\n",
    "                foreground = frame\n",
    "                \n",
    "            # If sketching dancers is enabled\n",
    "            if self.sketch_persons:\n",
    "                sketch = self.sketch_frame(foreground, mask)\n",
    "                final = sketch\n",
    "            else:\n",
    "                final = foreground\n",
    "\n",
    "            # Debug red edges\n",
    "            if self.show_personEdge:\n",
    "                edges = cv2.Canny((mask * 255).astype(np.uint8), 80, 180)\n",
    "                final[edges != 0] = [255, 0, 0]\n",
    "\n",
    "            processed_frames.append(final)\n",
    "\n",
    "        out_clip = ImageSequenceClip(processed_frames, fps=clip.fps)\n",
    "        out_clip.write_videofile(self.output_path, codec=\"libx264\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "537c6992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Image loaded successfully.\n",
      "Moviepy - Building video output_tango1_v15.mp4.\n",
      "Moviepy - Writing video output_tango1_v15.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready output_tango1_v15.mp4\n"
     ]
    }
   ],
   "source": [
    "#setup prompt and background image\n",
    "prompt_face = \"\"\"\n",
    "Replace face with a generic, unrecognizable synthetic face of a young adult male/female with neutral expression\n",
    "\"\"\"\n",
    "\n",
    "bg = cv2.imread(\"./backstage/white.png\")  # or \"dancefloor.jpg\"\n",
    "\n",
    "if bg is None:\n",
    "    print(\"❌ Image not found or failed to load.\")\n",
    "    exit()\n",
    "else:\n",
    "    print(\"✅ Image loaded successfully.\")\n",
    "\n",
    "\n",
    "img = np.full((512, 512, 3), 220, dtype=np.uint8)\n",
    "pil_bg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "editor = SketchDanceEditor(\n",
    "    input_path=\"./solus/tango1.mp4\",\n",
    "    output_path=\"output_tango1_v15.mp4\",\n",
    "    clipsec=(0,15),\n",
    "    background_mode=\"none\",      # \"color\", \"image\", \"none\"\n",
    "    background_color=(210, 210, 210),\n",
    "    background_image=None,\n",
    "    show_personEdge=True,\n",
    "    sketch_persons=True\n",
    ")\n",
    "editor.process_video()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aimovie",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
